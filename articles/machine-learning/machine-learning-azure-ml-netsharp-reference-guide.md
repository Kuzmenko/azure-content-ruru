<properties 
	pageTitle="Руководство по языку спецификаций нейронных сетей Net# | Microsoft Azure" 
	description="Синтаксис языка спецификации нейронных сетей Net# и примеры создания пользовательской модели нейронной сети в Microsoft Azure ML с помощью Net#" 
	services="machine-learning" 
	documentationCenter="" 
	authors="jeannt" 
	manager="jhubbard" 
	editor="cgronlun"/>

<tags 
	ms.service="machine-learning" 
	ms.workload="data-services" 
	ms.tgt_pltfrm="na" 
	ms.devlang="na" 
	ms.topic="article" 
	ms.date="09/12/2016" 
	ms.author="jeannt"/>



# Руководство по языку спецификаций нейронных сетей Net# для машинного обучения Azure

## Обзор
Net# — это язык, разработанный Майкрософт для использования при определении архитектур нейронных сетей для модулей нейронных сетей, которые применяются в Машинном обучении Microsoft Azure. В этой статье вы узнаете следующее:

-	Основные понятия, связанные с нейронными сетями
-	Требования к нейронным сетям и определения основных компонентов
-	Синтаксис и ключевые слова языка спецификаций Net#
-	Примеры настраиваемых нейронных сетей, созданных с использованием Net#
	
[AZURE.INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## Основы нейронных сетей
Структура нейронной сети состоит из ***узлов***, организованных в ***слои***, и взвешенных ***подключений*** (или ***переходов***) между узлами. Подключения при этом являются направленными, и для каждого из них задан узел ***источника*** и узел ***назначения***.

У каждого ***обучаемого слоя*** (скрытого или выходного) есть один или несколько ***пакетов подключений***. Пакет подключений состоит из слоя источника и спецификации подключений из этого слоя источника. Все подключения в любом пакет совместно используют один и тот же ***слой источника*** и тот же ***слой назначения***. В Net# считается, что пакет подключений относится к слою назначения пакета.
 
Net# поддерживает различные виды пакетов подключений, которые позволяют настраивать способ сопоставления входов со скрытыми слоями и выходами.

Пакет по умолчанию или стандартный пакет называется **полным пакетом**. В таком пакете каждый узел в слое источника подключается к каждому узлу в слое назначения.

В дополнение к этому, Net# поддерживает следующие четыре типа дополнительных пакетов подключения:

-	**Фильтрованные пакеты**. Пользователь может задавать предикат с использованием мест назначения узла слоя источника и узла слоя назначения. Узлы подключаются, если предикат имеет значение True.
-	**Сверточные пакеты**. Пользователь может задавать небольшие окрестности узлов в слое источника. Каждый узел в слое назначения подключается к одной окрестности узлов в слое источника.
-	**Группирующие пакеты** и **пакеты нормализации ответов**. Эти пакеты аналогичны сверточным пакетам в том смысле, что пользователь определяет небольшие окрестности узлов в слое источника. Различие заключается в том, что в таких пакетах не поддерживается обучение по весам переходов. Вместо этого для определения значения узла назначения к узлу источника применяется предопределенная функция.

Использование Net# для определения структуры нейронной сети позволяет задавать такие сложные структуры, как глубокие нейронные сети или свертки произвольных размеров для улучшения обучения на основе данных — изображений, аудио и видео.

## Поддерживаемые настройки
Архитектура моделей нейронных сетей, создаваемых в Машинном обучении Azure, может широко настраиваться с помощью Net#. Вы можете:

-	Создавать скрытые слои и управлять количеством узлов в каждом слое.
-	Задавать способ подключения слоев друг к другу.
-	Определять специальные структуры подключения, такие как свертки и пакеты с распределением весов.
-	Задавать различные функции активации.

Подробную информацию о синтаксисе языка спецификаций см. в разделе [Спецификация структуры](#Structure-specifications).
 
Примеры определения нейронных сетей для некоторых общих задач машинного обучения от простого к сложному см. в разделе [Примеры](#Examples-of-Net#-usage).

## Общие требования
-	Должен быть точно один выходной слой, как минимум один входной слой, а также ноль или более скрытых слоев.
-	Каждый слой имеет фиксированное количество узлов, концептуально организованных в прямоугольную матрицу произвольных размеров.
-	Входные слои не имеют связанных обученных параметров и представляют собой точку, в которой данные экземпляра входят в сеть.
-	С обучаемыми слоями (скрытыми и выходными) связаны обученные параметры, известные как веса и смещения.
-	Узлы источника и назначения должны находиться в отдельных слоях.
-	Подключения должны быть ациклическими. Другими словами, не должно быть цепочки подключений, ведущей назад к исходному узлу источника.
-	Выходной слой не должен быть слоем источника пакета подключений.

## Спецификация структуры
Спецификация структуры нейронной сети состоит из трех разделов: **объявления констант**, **объявления слоев**, **объявления подключений** и дополнительного раздела **объявления общего доступа**. Указанные разделы могут задаваться в любом порядке.

## Объявление констант 
Объявление констант является необязательным. Этот раздел предоставляет средство, позволяющее задать значения, используемые в определении нейронной сети. Оператор объявления состоит из идентификатора, за которым следует знак равенства и выражение значения.

Например, следующий оператор задает константу **x**:


    Const X = 28;  

Для одновременного определения двух или более констант заключите имена и значения идентификаторов в кавычки и разделите их точками с запятой. Например:

    Const { X = 28; Y = 4; }  

Правая сторона каждого выражения присваивания может быть целым числом, вещественным числом, логическим значением (true/false (истина/ ложь)) или математическим выражением. Например:

	Const { X = 17 * 2; Y = true; }  

## Объявление слоев
Слои нужно обязательно объявить. При этом определяется размер и источник слоя, в том числе его пакеты подключений и атрибуты. Определение начинается с имени слоя (входной, скрытый или выходной), за которым следует размер слоя (набор целых положительных чисел). Например:

	input Data auto;
	hidden Hidden[5,20] from Data all;
	output Result[2] from Hidden all;  

-	Произведение измерений представляет собой количество узлов слоя. В нашем примере указано два измерения [5,20]. Это означает, что в слое имеется 100 узлов.
-	Слои можно объявлять в любом порядке, с одним исключением: если определяется более одного входного слоя, порядок, в котором они объявляются, должен соответствовать порядку признаков во входных данных.


Чтобы задать автоматическое определение количества узлов слоя, используйте ключевое слово **auto**. Ключевое слово **auto** имеет различное действие в зависимости от слоя:

-	При объявлении входного слоя количество узлов представляет собой количество функций во входных данных.
-	При объявлении скрытого слоя количество узлов определяется параметром **Количество скрытых узлов**.
-	При объявлении выходного слоя количество узлов равняется 2 для двухклассной классификации, 1 — для регрессии и равно количеству выходных узлов для многоклассовой классификации.

Например, следующее определение сети позволяет автоматически определять размер всех слоев:

	input Data auto;
	hidden Hidden auto from Data all;
	output Result auto from Hidden all;  


Определение слоя для обучаемого слоя (скрытых или выходных слоев) может содержать выходную функцию (также называемую функцией активации). По умолчанию для моделей классификации используется функция **sigmoid**, а для моделей регрессии — функция **linear**. (Даже если используется значение по умолчанию, при желании можно указать функцию активации явно для ясности.)

Поддерживаются следующие выходные функции:

-	sigmoid
-	linear
-	softmax
-	rlinear
-	square
-	sqrt
-	srlinear
-	abs
-	tanh
-	brlinear

Например, в следующем объявлении используется функция **softmax**:

	output Result [100] softmax from Hidden all;  

## Объявление подключений
Сразу после определения обучаемого слоя необходимо объявить подключения среди слоев, которые были определены. Пакет подключений начинается с ключевого слова **from**, за которым располагается имя слоя источника пакета и указывается вид пакета подключений, который необходимо создать.

В настоящее время поддерживается пять видов пакетов подключений:

-	**Полные** пакеты, обозначаемые ключевым словом **all**.
-	**Фильтрованные** пакеты, обозначаемые ключевым словом **where** с расположенным за ним выражением предиката.
-	**Сверточные** пакеты, обозначаемые ключевым словом **convolve** с расположенными за ним атрибутами свертки.
-	**Группирующие** пакеты, обозначаемые ключевым словом **max pool** или **mean pool**.
-	Пакеты **нормализации ответов**, обозначаемые ключевым словом **response norm**.

## Полные пакеты  

Полный пакет подключения содержит подключение от каждого узла слоя источника к каждому узлу слоя назначения. Это тип сетевого подключения по умолчанию.

## Фильтрованные пакеты
Спецификация фильтрованного пакета подключений содержит предикат, выраженный синтаксически, практически так же, как лямбда-выражение в C#. В следующем примере определены два фильтрованных пакета:

	input Pixels [10, 20];
	hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
	hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

-	В предикате для _ByRow_ **s** — параметр, представляющий индекс прямоугольного массива узлов входного слоя _Pixels_, а **d** — параметр, представляющий индекс массива узлов скрытого слоя _ByRow_. Тип обоих **s** и **d** представляет собой кортеж целых чисел с длиной два. Концептуально **s** находится в диапазоне всех пар целых чисел с условиями _0 <= s[0] < 10_ and _0 <= s[1] < 20_, а **d** находится в диапазоне всех пар целых чисел с условиями _0 <= d[0] < 10_ и _0 <= d[1] < 12_.
-	На правой стороне выражения предиката находится условие. В этом примере для каждого значения **s** и **d**, условие которого имеет значение True, предусмотрен переход из узла слоя источника в узел слоя назначения. Таким образом, это выражение фильтра указывает, что пакет содержит подключение от узла, определенного параметром **s**, к узлу, определенному параметром **d**, во всех случаях, где s[0] равно d[0].

Дополнительно можно указать набор весов фильтрованного пакета. Значение атрибута **Weights** должно быть кортежем значений с плавающей запятой, длина которых соответствует количеству подключений, определенных пакетом. По умолчанию веса генерируются случайно.

Значения весов группируются по индексу узла назначения. То есть, если первый узел назначения подключен к исходным узлам K, то первые _K_ элементов кортежа **Weights** представляют собой веса для первого узла назначения в порядке индексов исходного узла. Это же правило применяется к остальным узлам назначения.

Параметры веса можно также задать как постоянные величины. Например, если параметры веса вам уже известны, вы можете указать их как постоянные величины, используя следующий синтаксис:

	const Weights_1 = [0.0188045055, 0.130500451, ...]


## Сверточные пакеты
В случаях, когда данные для обучения имеют однородную структуру, сверточные подключения широко используются для обучения высокоуровневых признаков данных. Например, изображение, аудио- или видеоданные, пространственная или временная размерность могут быть достаточно однородными.

Сверточные пакеты используют прямоугольные **ядра**, которые перемещаются по измерениям. По существу, каждое ядро определяет набор весов, применяемый в локальных окрестностях, который называются **приложениями ядра**. Каждое приложение ядра соответствует узлу в слое источника, который называется **центральным узлом**. Веса ядра используются совместно во многих подключениях. В сверточных пакетах каждое ядро представляет собой прямоугольник, а все приложения ядра имеют одинаковый размер.

Сверточные пакеты поддерживают следующие атрибуты:

**InputShape** — определяет размерность слоя источника в целях данного сверточного пакета. Значение должно быть кортежем целых чисел. Произведение целых чисел должно равняться количеству узлов слоя источника, однако в противном случае необязательно должно соответствовать размерности, объявленной для слоя источника. Длина этого кортежа становится значением **арности** для сверточного пакета. (Как правило, арность относится к количеству аргументов или операндов, которое может принимать функция.)

Чтобы определить форму и местоположение ядер, используйте атрибуты **KernelShape**, **Stride**, **Padding**, **LowerPad** и **UpperPad**.

-	**KernelShape** (обязательный): определяет размерность каждого ядра сверточного пакета. Значение должно быть кортежем положительных целых чисел, длина которых равна арности пакета. Каждый компонент этого кортежа должен быть не больше, чем соответствующий компонент атрибута **InputShape**.
-	**Stride** (необязательный): определяет размер шага скольжения свертки (размер одного шага для каждого измерения), т. е. расстояние между центральными узлами. Значение должно быть кортежем положительных целых чисел, длина которых равна арности пакета. Каждый компонент этого кортежа должен быть не больше, чем соответствующий компонент атрибута **KernelShape**. Значение по умолчанию: кортеж со всеми компонентами, равными единице.
-	**Sharing** (необязательный): определяет вес, общий для каждого измерения свертки. Значение может быть одним логическим значением или кортежем логических значений, длина которых представляет собой арность пакета. Одно логическое значение расширяется до кортежа нужной длины со всеми компонентами, равными определенному значению. Значение по умолчанию — кортеж, состоящий из всех значений True.
-	**MapCount** (необязательный): определяет количество карт функций для сверточного пакета. Значение может быть одним положительным целым числом или кортежем положительных целых, длина которых представляет собой арность пакета. Одно целое значение расширяется до кортежа нужной длины с первыми компонентами, равными определенному значению, а оставшимися компонентами, равными единице. По умолчанию значение равно единице. Общее количество карт функций представляет собой произведение компонентов кортежа. Разложение этого общего количества по компонентам определяет, каким образом группируются значения карт функций в узлах назначения.
-	**Weights** (необязательный) определяет исходные веса для пакета. Значение должно быть кортежем значений с плавающей запятой, длина которых представляет собой количество ядер, умноженное на количество весов на ядро, как указано ниже в этой статье. Веса по умолчанию генерируются случайно.

Существует два набора свойств для управления заполнением, которые являются взаимоисключающими.

-	**Padding** (необязательно): определяет, должен ли вход заполняться с использованием **схемы заполнения по умолчанию**. Значение может быть одним логическим значением или кортежем логических значений, длина которых представляет собой арность пакета. Одно логическое значение расширяется до кортежа нужной длины со всеми компонентами, равными определенному значению. Если измерение имеет значение True, источник логически заполняется в этом измерении ячейками с нулевыми значениями для поддержки дополнительных приложений ядра таким образом, чтобы центральные узлы первого и последнего ядер в этом измерении представляли собой первый и последний узел в этом измерении слоя источника. Таким образом, количество «пустых» узлов в каждом измерении определяется автоматически для точного соответствия _(InputShape[d] - 1) / Stride[d] + 1_ ядрам в заполненном слое источника. Если измерение имеет значение False, ядра определяются таким образом, чтобы количество оставшихся узлов на каждой стороне было одинаковым (до разницы в 1). Значение по умолчанию этого атрибута: кортеж со всеми компонентами, равными False.
-	**UpperPad** и **LowerPad** (необязательно): позволяют более тонко управлять объемом заполнения. **Важно:** Эти атрибуты могут задаваться тогда и только тогда, когда свойство **Padding** выше ***не*** задается. Значения должны быть кортежами с целыми значениями, длина которых представляет собой арность пакета. При задании этих атрибутов «пустые» узлы добавляются к нижнему и верхнему концам каждого измерения входного слоя. Количество узлов, добавленных к нижнему и верхнему концам в каждом измерении, определяется атрибутами **LowerPad[i]** и **UpperPad[i]** соответственно. Чтобы обеспечить соответствие количества ядер только количеству «реальных», а не «пустых» узлов, должны выполняться следующие условия.
	-	Каждый компонент атрибута **LowerPad** должен быть строго меньше, чем KernelShape[d]/2.
	-	Каждый компонент атрибута **UpperPad** должен быть не больше, чем KernelShape[d]/2.
	-	Значение по умолчанию этих атрибутов: кортеж со всеми компонентами, равными 0.

Значение **Padding** = true позволяет осуществить максимально необходимое заполнение для сохранения «центра» ядра внутри «реального» входа. Поэтому формула для вычисления выходного размера немного изменяется. Обычно выходной размер _D_ вычисляется как _D = (I - K) / S + 1_, где _I_ - входной размер, _K_ - размер ядра, _S_ - шаг и _/_ - целочисленное деление (с округлением до нуля). Если задать значение UpperPad = [1, 1], то входной размер _I_ по сути равен 29, и поэтому _D = (29 - 5) / 2 + 1 = 13_. Однако если **Padding** = true, то и _I_ фактически выталкивается _K - 1_; следовательно _D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14_. Если задать значения параметров **UpperPad** и **LowerPad**, то можно получить гораздо больший контроль над заполнением по сравнению с тем случаем, если задан только параметр **Padding** = true.

Дополнительную информацию о сверточных сетях и их приложениях см. в следующих статьях:

-	[http://deeplearning.net/tutorial/lenet.html ](http://deeplearning.net/tutorial/lenet.html)
-	[http://research.microsoft.com/pubs/68920/icdar03.pdf ](http://research.microsoft.com/pubs/68920/icdar03.pdf)
-	[http://people.csail.mit.edu/jvb/papers/cnn\_tutorial.pdf](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)

## Группирующие пакеты
**Группирующий пакет** применяет геометрию, аналогичную сверточному подключению, но использует предопределенные функции для значений узла источника, чтобы извлечь значение узла назначения. Следовательно, группирующие пакеты не имеют обучаемого состояния (весов или смещений). Группирующие пакеты поддерживают все сверточные атрибуты, за исключением **Sharing**, **MapCount** и **Weights**.

Как правило, ядра, суммированные соседними группирующими модулями, не перекрываются. Если Stride[d] равен KernelShape[d] в каждом измерении, то полученный слой представляет собой традиционный локальный группирующий слой, который обычно используется в сверточных нейронных сетях. Каждый узел назначения вычисляет максимальное или среднее значение действий своего ядра в слое источника.

В следующем примере проиллюстрирован группирующий пакет:

	hidden P1 [5, 12, 12]
	  from C1 max pool {
	    InputShape  = [ 5, 24, 24];
	    KernelShape = [ 1,  2,  2];
	    Stride      = [ 1,  2,  2];
	  }  

-	Арность пакета равна 3 (длина кортежей **InputShape**, **KernelShape** и **Stride**).
-	Количество узлов в слое источника: _5 * 24 * 24 = 2880_.
-	Это традиционный локальный группирующий слой, так как **KernelShape** и **Stride** равны.
-	Количество узлов в слое назначения: _5 * 12 * 12 = 1440_.
	
Дополнительную информацию о группирующих слоях см. в статьях:

-	[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (раздел 3.4)
-	[http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf)
-	[http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)
	
## Пакеты нормализации ответов
**Нормализация ответов** представляет собой локальную схему нормализации, которая впервые была предложена Джеффри Хинтоном (Geoffrey Hinton) и др. в статье под названием [Классификация ImageNet с помощью глубоких сверточных нейронных сетей](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf). Нормализация ответов используется для облегчения обобщения в нейронных сетях. Когда один нейрон срабатывает при очень высоком уровне активации, локальный слой нормализации ответа подавляет уровень активации окружающих нейронов. Это выполняется с использованием трех параметров (***α***, ***β*** и ***k***) и сверточной структуры (или формы окрестности). Каждый нейрон в слое назначения ***y*** соответствует нейрону ***x*** в слое источника. Уровень активации ***y*** задается следующей формулой, где ***f*** — уровень активации нейрона, ***Nx*** — ядро (или набор, содержащий нейроны в окрестности ***x***), как определяется сверточной структурой.

![][1]

Пакеты нормализации ответов поддерживают все сверточные атрибуты, за исключением **Sharing**, **MapCount** и **Weights**.
 
-	Если ядро содержит нейроны в той же карте, что и ***x***, схема нормализации называется **нормализация в той же карте**. Чтобы задать нормализацию в той же карте, первая координата в **InputShape** должна иметь значение 1.
-	Если ядро содержит нейроны в той же пространственной позиции, что и ***x***, но нейроны находятся в других картах, схема нормализации называется **межкарточной нормализацией**. Этот тип нормализации ответа реализует форму латерального торможения, похожую на форму, найденную у реальных нейронов, создавая конкуренцию за большие уровни активации среди выходов нейронов, вычисленных на различных картах. Чтобы задать межкарточную нормализацию, первая координата должна быть целым числом (больше единицы и не больше количества карт), а остальные координаты должны иметь значения, равные 1.

Так как пакеты нормализации ответов применяют предопределенную функцию к значениям узла источника для определения значения узла назначения, они не имеют обучаемого состояния (веса или смещения)

**Alert**: узлы в слое назначения соответствуют нейронам, которые представляют собой центральные узлы ядер. Например, если KernelShape[d] имеет нечетное значение, то _KernelShape[d]/2_ соответствует центральному узлу ядра. Если значение _KernelShape[d]_ четное, центральный узел находится в _KernelShape[d]/2 - 1_. Таким образом, если для параметра **Padding**[d] задано значение False, то первый и последний узлы _KernelShape[d]/2_ не имеют соответствующих узлов в слое назначения. Чтобы исключить эту ситуацию, задайте атрибут **Padding** как [true, true, …, true].

В дополнение к четырем атрибутам, описанным выше, пакеты нормализации ответов также поддерживают следующие атрибуты.

-	**Alpha** (обязательный): определяет значение с плавающей запятой, соответствующее ***α*** в указанной выше формуле.
-	**Beta** (обязательный): определяет значение с плавающей запятой, соответствующее ***β*** в указанной выше формуле.
-	**Offset** (необязательный): определяет значение с плавающей запятой, соответствующее ***k*** в указанной выше формуле. Его значение по умолчанию равно 1.

В следующем примере определяется пакет нормализации ответов с использованием этих атрибутов:

	hidden RN1 [5, 10, 10]
	  from P1 response norm {
	    InputShape  = [ 5, 12, 12];
	    KernelShape = [ 1,  3,  3];
	    Alpha = 0.001;
	    Beta = 0.75;
	  }  

-	Слой источника содержит пять карт, каждая размером 12 x 12, и в общей сложности насчитывает 1440 узлов.
-	Значение **KernelShape** указывает, что это та же карта слоя нормализации, в которой окрестность представляет собой прямоугольник 3x3.
-	По умолчанию атрибут **Padding** имеет значение False, следовательно, у слоя назначения в каждом измерении буде только 10 узлов. Чтобы включить один узел в слое назначения, соответствующий каждому узлу в слое источника, добавьте Padding = [true, true, true] и измените размер RN1 на [5, 12, 12].

## Объявление общего доступа 
Net# дополнительно поддерживает определение нескольких пакетов с общими весами. Веса любых двух пакетов могут быть общими, если их структуры одинаковы. Далее описывается синтаксис определения пакетов с общими весами:

	share-declaration:
	    share    {    layer-list    }
	    share    {    bundle-list    }
	   share    {    bias-list    }
	
	layer-list:
	    layer-name    ,    layer-name
	    layer-list    ,    layer-name
	
	bundle-list:
	   bundle-spec    ,    bundle-spec
	    bundle-list    ,    bundle-spec
	
	bundle-spec:
	   layer-name    =>     layer-name
	
	bias-list:
	    bias-spec    ,    bias-spec
	    bias-list    ,    bias-spec
	
	bias-spec:
	    1    =>    layer-name
	
	layer-name:
	    identifier  

Например, следующее объявление общего доступа определяет имена слоев, указывая, что веса и смещения должны быть общими.

	Const {
	  InputSize = 37;
	  HiddenSize = 50;
	}
	input {
	  Data1 [InputSize];
	  Data2 [InputSize];
	}
	hidden {
	  H1 [HiddenSize] from Data1 all;
	  H2 [HiddenSize] from Data2 all;
	}
	output Result [2] {
	  from H1 all;
	  from H2 all;
	}
	share { H1, H2 } // share both weights and biases  

-	Входные функции разделяются на два входных слоя одинаковых размеров.
-	Скрытые слои далее вычисляют функции более высокого уровня на двух входных слоях.
-	Объявление общего доступа определяет, что _H1_ и _H2_ должны вычисляться одинаково из их соответствующих входов.
 
В качестве альтернативы это можно задать с помощью двух отдельных объявлений общего доступа следующим образом:

	share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

	share { 1 => H1, 1 => H2 } // share biases  

Краткую форму можно использовать только, если слои содержат один пакет. Как правило, общий доступ возможен, только если соответствующие структуры идентичны, то есть имеют один размер, одинаковую сверточную геометрию и т. д.

## Примеры использования Net#
В этом разделе приводится несколько примеров использования Net# для добавления скрытых слоев, определения способов взаимодействия скрытых слоев с другими слоями и построения сверточных сетей.

### Определение простой настраиваемой нейронной сети: пример «Привет, мир!»
В этом простом примере показано, как создавать модель нейронной сети с одним скрытым слоем.

	input Data auto;
	hidden H [200] from Data all;
	output Out [10] sigmoid from H all;  

В примере проиллюстрированы некоторые базовые команды и их порядок.

-	В первой строке определяется входной слой (с именем _Data_). При использовании ключевого слова **auto** в нейронную сеть автоматически включаются все столбцы функций в примерах ввода.
-	Вторая строка создает скрытый слой. Имя _H_ назначается скрытому слою с 200 узлами. Этот слой полностью подключен ко входному слою.
-	Третья строка определяет выходной слой (с именем _O_), который содержит 10 выходных узлов. Для классификации нейронных сетей используется по одному выходному узлу на класс. Ключевое слово **sigmoid** указывает выходную функцию, примененную к выходному слою.

### Определение нескольких скрытых слоев: пример машинного зрения
В следующем примере показано, как определять немного более сложную нейронную сеть с несколькими настраиваемыми скрытыми слоями.

	// Define the input layers 
	input Pixels [10, 20];
	input MetaData [7];
	
	// Define the first two hidden layers, using data only from the Pixels input
	hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
	hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;
	
	// Define the third hidden layer, which uses as source the hidden layers ByRow and ByCol
	hidden Gather [100] 
	{
	  from ByRow all;
	  from ByCol all;
	}
	
	// Define the output layer and its sources
	output Result [10]  
	{
	  from Gather all;
	  from MetaData all;
	}  

В примере проиллюстрировано несколько признаков языка спецификаций нейронных сетей

-	Структура имеет два входных слоя: _Pixels_ и _MetaData_.
-	Слой _Pixels_ — это слой источника для двух пакетов подключений со слоями назначения: _ByRow_ и _ByCol_.
-	Слои _Gather_ и _Result_ — это слои назначения в нескольких пакетах подключений.
-	Выходной слой _Result_ представляет собой слой назначения в двух пакетах подключений: один — со скрытым слоем второго уровня (Gather) в качестве слоя назначения и другой — с входным слоем (MetaData) в качестве слоя назначения.
-	Скрытые слои _ByRow_ и _ByCol_ определяют отфильтрованные подключения с использованием выражений предиката. Если говорить точнее, то узел в _ByRow_ с координатами [x, y] подключается к тем узлам в _Pixels_, у которых первая координата индекса равна первой координате узла (x). Аналогично узел ByCol с координатами [x, y] подключается к тем узлам в _Pixels_, у которых вторая координата индекса находится в пределах единицы от второй координаты узла (у).

### Определение сверточной сети для многоклассовой классификации: пример распознавания цифр
Определение следующей сети, разработанной для распознавания цифр, показывает некоторые усовершенствованные методы настройки нейронных сетей.

	input Image [29, 29];
	hidden Conv1 [5, 13, 13] from Image convolve 
	{
	   InputShape  = [29, 29];
	   KernelShape = [ 5,  5];
	   Stride      = [ 2,  2];
	   MapCount    = 5;
	}
	hidden Conv2 [50, 5, 5]
	from Conv1 convolve 
	{
	   InputShape  = [ 5, 13, 13];
	   KernelShape = [ 1,  5,  5];
	   Stride      = [ 1,  2,  2];
	   Sharing     = [false, true, true];
	   MapCount    = 10;
	}
	hidden Hid3 [100] from Conv2 all;
	output Digit [10] from Hid3 all;  


-	Структура имеет один входной слой — _изображение_.
-	Ключевое слово **convolve** указывает, что _Conv1_ и _Conv2_ — сверточные слои. За объявлением каждого из этих слоев следует список атрибутов свертки.
-	У сети имеется третий скрытый слой _Hid3_, который полностью подключен ко второму скрытому слою _Conv2_.
-	Выходной слой _Digit_ подключен к третьему скрытому слою _Hid3_. Ключевое слово **all** указывает, что выходной слой полностью подключен к _Hid3_.
-	Арность свертки — три (длина кортежей **InputShape**, **KernelShape**, **Stride** и **Sharing**).
-	Количество весов на ядро равно: _1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300_.
-	Количество узлов в каждом скрытом слое можно вычислить следующим образом:
	-	**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.
	-	**NodeCount**\[1] = (13 – 5) / 2 + 1 = 5. 
	-	**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5. 
-	Общее количество узлов можно вычислить, используя объявленную размерность слоя [50, 5, 5] следующим образом: _**MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5_
-	Так как **Sharing**[d] имеет значение False только для _d == 0_, то количество ядер равно _**MapCount** * **NodeCount**\[0] = 10 * 5 = 50_.


## Благодарности

Язык Net# для изменения архитектуры нейронных сетей был разработан в корпорации Майкрософт Шоном Катценбергером [Shon Katzenberger]\(архитектор, машинное обучение) и Алексеем Каменевым (разработчик программного обеспечения, Microsoft Research). Он используется внутри компании для проектов машинного обучения и различных приложений от приложений распознавания образов до приложений анализа текста. Дополнительные сведения см. в разделе [Нейронные сети в Azure ML. Введение в Net#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx).


[1]: ./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif
 

<!----HONumber=AcomDC_0914_2016-->
