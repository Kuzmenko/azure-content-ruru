<properties
	pageTitle="Задания по масштабированию в Azure Stream Analytics для увеличения пропускной способности | Microsoft Azure"
	description="Узнайте, как масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи."
	keywords="потоковая передача данных, обработка потоковой передачи данных, настройка аналитики"
	services="stream-analytics"
	documentationCenter=""
	authors="jeffstokes72"
	manager="jhubbard"
	editor="cgronlun"/>

<tags
	ms.service="stream-analytics"
	ms.devlang="na"
	ms.topic="article"
	ms.tgt_pltfrm="na"
	ms.workload="data-services"
	ms.date="07/27/2016"
	ms.author="jeffstok"/>

# Масштабирование заданий Azure Stream Analytics для повышения пропускной способности базы данных

Узнайте, как настраивать задания аналитики, вычислять *единицы потоковой передачи* для Stream Analytics и масштабировать задания Stream Analytics с помощью настройки входных разделов, настройки определения запроса и определения единиц потоковой передачи.

## Из каких частей состоит задание службы Stream Analytics?
Определение задания Stream Analytics включает запрос, а также входные и выходные данные. Входные данные – это точки, откуда задания считывают данные из потока, запрос используется для преобразования потока входных данных, а выходные данные являются точками, куда направляются результаты задания.

Задание требует по крайней мере один источник входных данных для потока данных. Входной источник потока данных может храниться в концентраторе событий служебной шины Azure или в хранилище больших двоичных объектов Azure. Дополнительные сведения см. в статьях [Что такое Stream Analytics?](stream-analytics-introduction.md) и [Приступая к работе с Azure Stream Analytics: выявление мошенничества в режиме реального времени](stream-analytics-get-started.md).

## Настройка единиц потоковой передачи
Единицы потоковой передачи представляют ресурсы и мощность, необходимые для выполнения задания Azure Stream Analytics. Единицы потоковой передачи предоставляют способ описания относительной мощности обработки события, основываясь на измерении загрузки ЦП, памяти и скорости чтения и записи. Каждая единица потоковой передачи соответствует пропускной способности около 1 МБ/с.

Выбор необходимого количества единиц потоковой передачи для конкретного задания зависит от конфигурации раздела для входных данных и запроса, определенного для задания. На классическом портале Azure для каждого задания можно выбрать количество единиц потоковой передачи согласно указанной квоте. Каждая подписка Azure по умолчанию включает в себя квоту до 50 единиц потоковой передачи для всех заданий аналитики в определенном регионе. Чтобы увеличить количество единиц потоковой передачи для своей подписки, свяжитесь со [службой технической поддержки Майкрософт](http://support.microsoft.com).

Число единиц потоковой передачи для использования в одном задании зависит от конфигурации раздела для входных данных и запроса, определенного для задания. Обратите внимание, что необходимо использовать допустимое значение единиц потоковой передачи. Допустимые значения начинаются с 1, 3, 6 и затем по возрастающей с шагом в 6, как показано ниже.

![Масштабирование единиц потоковой передачи Azure Stream Analytics][img.stream.analytics.streaming.units.scale]

В этой статье показано, как вычислить и настроить запрос для увеличения пропускной способности аналитических заданий.

## Задание с усложненным параллелизмом
Задание с усложненным параллелизмом — это самый масштабируемый сценарий в Azure Stream Analytics. Он соединяет один раздел входных данных с одним экземпляром запроса и одним разделом выходных данных. Для достижения такого параллелизма должны соблюдаться несколько условий:

1.  Если в логике запроса применяется ключ, который обрабатывается тем же экземпляром запроса, необходимо только проследить за тем, чтобы события попадали в тот же раздел входных данных. При использовании концентраторов событий это означает, что данные событий должны включать набор **PartitionKey** или вы можете использовать секционированные отправители. Для BLOB-объектов это означает, что события отправляются в папку того же раздела. Если логика запроса не требует обработки ключа тем же экземпляром запроса, это требование можно проигнорировать. В качестве примера можно привести простой запрос select, project или filter.
2.	После того как данные будут распределены в нужном для источника данных порядке, необходимо убедиться в том, что запрос разбит на разделы. Для этого на каждом этапе используется параметр **Partition By**. Этапов может быть несколько, но на каждом из них должен использоваться один и тот же ключ. Другой момент, который следует отметить, связан с тем, что сейчас для выполнения заданий с параллелизмом необходимо использовать параметр **PartitionId** в качестве ключа секционирования.
3.	На данном этапе секционированные выходные данные поддерживаются только концентраторами событий и BLOB-объектами. Для выходных данных концентраторов событий необходимо указать в поле **PartitionKey** значение **PartitionId**. Для BLOB-объектов ничего делать не нужно.
4.	Кроме того, число разделов входных данных должно совпадать с числом разделов выходных данных. Выходные данные BLOB-объектов в настоящее время не поддерживают разделы, но в этом нет ничего страшного, поскольку они наследуют схемы секционирования вышестоящего запроса. Примеры значений разделов, позволяющие выполнять задания с полной параллельной обработкой:
	1.	8 разделов входных данных концентраторов событий и 8 разделов выходных данных концентраторов событий
	2.	8 разделов входных данных концентраторов событий и выходные данные BLOB-объектов
	3.	8 разделов входных данных BLOB-объектов и выходные данные BLOB-объектов
	4.	8 разделов входных данных BLOB-объектов и 8 разделов выходных данных концентраторов событий

Рассмотрим примеры сценариев с усложненным параллелизмом.

### Простой запрос
Входные данные — концентраторы событий с 8 разделами. Выходные данные — концентратор событий с 8 разделами

**Запрос**

    SELECT TollBoothId
    FROM Input1 Partition By PartitionId
    WHERE TollBoothId > 100

Это — простой запрос filter, поэтому о секционировании входных данных, отправляемых в концентраторы событий, беспокоиться не нужно. Как видите, запрос содержит параметр **Partition By** со значением **PartitionId**, а значит, выполнено указанное выше второе требование. Выходные данные концентраторов событий необходимо настроить, указав в поле **PartitionKey** значение **PartitionId**. Последняя проверка: число разделов входных данных равно числу разделов выходных данных. Данная топология является топологией с усложненным параллелизмом.

### Запрос с ключом группирования
Входные данные — концентраторы событий с 8 разделами. Выходные данные — BLOB-объект

**Запрос**

    SELECT COUNT(*) AS Count, TollBoothId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Этот запрос содержит ключ группирования, а значит, этот ключ должен обрабатываться тем же экземпляром запроса. Это означает, что события нужно отправлять в концентраторы событий с делением на разделы. На какой ключ следует обращать внимание? Ключ **PartitionId** определяет логику задания, но обратить внимание следует на ключ **TollBoothId**. Это значит, что ключ **PartitionKey** данных события, отправляемый в концентраторы событий, должен быть указан как ключ **TollBoothId** события. Запрос содержит параметр **Partition By** со значением **PartitionId**, значит, все в порядке. Поскольку речь идет о выходных данных большого двоичного объекта, настраивать параметр **PartitionKey** не нужно. Требование 4 к BLOB-объектам также не относится. Данная топология является топологией с усложненным параллелизмом.

### Многоэтапный запрос с ключом группирования ###
Входные данные — концентратор событий с 8 разделами. Выходные данные — концентратор событий с 8 разделами

**Запрос**

    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Этот запрос содержит ключ группирования, а значит, этот ключ должен обрабатываться тем же экземпляром запроса. Мы используем ту же стратегию, что и для предыдущего запроса. Запрос состоит из нескольких этапов. Указан ли на каждом этапе параметр **Partition By** со значением **PartitionId**? Да, все в порядке. В выходных данных необходимо задать для параметра **PartitionKey** значение **PartitionId**, как описано выше. Выходные данные содержат столько же секций, сколько и входные. Данная топология является топологией с усложненным параллелизмом.


## Примеры сценариев БЕЗ усложненного параллелизма

### Несоответствие в числе разделов ###
Входные данные — концентраторы событий с 8 разделами. Выходные данные — концентратор событий с 32 разделами

Независимо от типа запроса, в этом случае число разделов входных данных не совпадает с числом разделов выходных данных.

### Для выходных данных не используются концентраторы событий или BLOB-объекты
Входные данные — концентраторы событий с 8 разделами. Выходные данные — PowerBI

В настоящее время выходные данные PowerBI не поддерживают секционирование.

### Многоэтапный запрос с разными значениями параметра Partition By
Входные данные — концентратор событий с 8 разделами. Выходные данные — концентратор событий с 8 разделами

**Запрос**

    WITH Step1 AS (
    SELECT COUNT(*) AS Count, TollBoothId, PartitionId
    FROM Input1 Partition By PartitionId
    GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
    )
    
    SELECT SUM(Count) AS Count, TollBoothId
    FROM Step1 Partition By TollBoothId
    GROUP BY TumblingWindow(minute, 3), TollBoothId
    
Как видите, на втором этапе в качестве ключа секционирования используется **TollBoothId**. Он не совпадает с ключом в первом шаге, а значит, потребует перетасовки.

Мы рассмотрели несколько примеров заданий Stream Analytics, соответствующих и не соответствующих критериям топологии с усложненным параллелизмом, а также максимально возможное для них масштабирование. Для заданий, не соответствующих ни одному из этих профилей, в дальнейшем будут выпущены обновления, рассказывающие, как добиваться максимального масштабирования в других традиционных сценариях Stream Analytics.

А пока придерживайтесь описанных ниже рекомендаций.

## Расчет максимального количества единиц потоковой передачи для задания
Общее число единиц потоковой передачи, которое можно использовать заданием Stream Analytics, зависит от числа шагов в запросе, определенных для задания, и количества разделов для каждого шага.

### Шаги в запросе
Запрос может иметь один или несколько шагов. Каждый шаг — это вложенный запрос, определенный с помощью ключевого слова **WITH**. Запрос за рамками ключевого слова **WITH** также учитывается в качестве шага (например, инструкция **SELECT** в следующем запросе).

	WITH Step1 AS (
		SELECT COUNT(*) AS Count, TollBoothId
		FROM Input1 Partition By PartitionId
		GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
	)

	SELECT SUM(Count) AS Count, TollBoothId
	FROM Step1
	GROUP BY TumblingWindow(minute,3), TollBoothId

Предыдущий запрос включает 2 шага.

> [AZURE.NOTE] Этот образец запроса будет описан далее в этой статье.

### Разделы шага

Разделение шага требует наличия следующих условий.

- Источник входных данных должен быть секционирован. Дополнительные сведения см. в [руководстве по программированию концентраторов событий](../event-hubs/event-hubs-programming-guide.md).
- Инструкция **SELECT** запроса должна читаться из разделенного источника входных данных.
- Запрос внутри шага должен включать ключевое слово **Partition By**.

Если запрос разделен, входные данные событий будут обработаны и объединены в отдельные группы секции, а выходные данные событий будут сгенерированы для каждой из групп. Если желательно иметь объединенный запрос, необходимо создать второй неразделенный шаг для объединения.

### Рассчитайте максимальное количество единиц потоковой передачи для задания

Все несекционированные шаги можно масштабировать до шести единиц потоковой передачи для задания Stream Analytics. Для добавления дополнительных единиц потоковой передачи данных шаг должен быть секционирован. Каждая секция может включать шесть единиц потоковой передачи.

<table border="1">
<tr><th>Запрос задания</th><th>Максимальное количество единиц потоковой передачи для задания</th></td>

<tr><td>
<ul>
<li>Запрос содержит один шаг.</li>
<li>Шаг не секционирован.</li>
</ul>
</td>
<td>6</td></tr>

<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос содержит один шаг.</li>
<li>Шаг является секционированным.</li>
</ul>
</td>
<td>18</td></tr>

<tr><td>
<ul>
<li>Запрос состоит из двух шагов.</li>
<li>Ни один из шагов не секционирован.</li>
</ul>
</td>
<td>6</td></tr>



<tr><td>
<ul>
<li>Поток входных данных секционирован по 3.</li>
<li>Запрос состоит из двух шагов. Входной шаг секционирован, а второй шаг — нет.</li>
<li>Инструкция SELECT считывает из секционированных входных данных.</li>
</ul>
</td>
<td>24 (18 и 6 секционированных и несекционированных шагов соответственно)</td></tr>
</table>

### Примеры масштабирования
Следующий запрос вычисляет количество машин, проходящих через пропускной пункт с тремя пунктами для оплаты и пропускной способности три минуты для каждого пункта. Этот запрос можно масштабировать до шести единиц потоковой передачи.

	SELECT COUNT(*) AS Count, TollBoothId
	FROM Input1
	GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Чтобы использовать дополнительные единицы потоковой передачи для запроса, входной поток данных и запрос должны быть секционированы. При наличии раздела потока данных, равного 3, следующий измененный запрос можно масштабировать до 18 единиц потоковой передачи.

	SELECT COUNT(*) AS Count, TollBoothId
	FROM Input1 Partition By PartitionId
	GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId

Если запрос секционирован, входные данные событий будут обработаны и объединены в отдельные группы секций. Кроме того, для каждой из групп будут сформированы выходные данные событий. Секционирование может вызвать некоторые непредвиденные результаты, если поле **Group-by** не является ключом секции во входном потоке данных. Например, поле **TollBoothId** в предыдущем примере запроса не является ключом секции Input1. Данные из пункта 1 можно распределить между несколькими секциями.

Каждая из секций Input1 будет обрабатываться отдельно с помощью Stream Analytics, и будет создаваться несколько записей для автомобиля, проходящего через один и тот же пункт. Если нельзя изменить ключ секции ввода, эту проблему можно устранить, добавив дополнительные несекционированные действия, например:

	WITH Step1 AS (
		SELECT COUNT(*) AS Count, TollBoothId
		FROM Input1 Partition By PartitionId
		GROUP BY TumblingWindow(minute, 3), TollBoothId, PartitionId
	)

	SELECT SUM(Count) AS Count, TollBoothId
	FROM Step1
	GROUP BY TumblingWindow(minute, 3), TollBoothId

Этот запрос можно увеличить до 24 единиц потоковой передачи.

>[AZURE.NOTE] При объединении двух потоков убедитесь, что потоки разделены с помощью ключа раздела для объединяемого столбца и количество разделов в обоих потоках одинаковое.


## Настройка раздела задания Stream Analytics

**Настройка единицы потоковой передачи для задания**

1. Войдите на [портал управления](https://manage.windowsazure.com).
2. Щелкните **Stream Analytics** в области слева.
3. Выберите задание Stream Analytics, которое необходимо расширить.
4. В верхней части страницы щелкните **МАСШТАБ**.

![Масштабирование единиц потоковой передачи Azure Stream Analytics][img.stream.analytics.streaming.units.scale]

На портале Azure параметры масштаба доступны в разделе "Параметры":

![Настройка задания Stream Analytics на портале Azure][img.stream.analytics.preview.portal.settings.scale]

## Мониторинг производительности задания

На портале управления можно отслеживать пропускную способность задания событий в секунду:

![Отслеживание заданий Azure Stream Analytics][img.stream.analytics.monitor.job]

Рассчитайте ожидаемую пропускную способность рабочей нагрузки событий в секунду. Если пропускная способность меньше, чем ожидалось, настройте входную секцию и запрос, а также добавьте в задание дополнительные единицы потоковой передачи.

## Масштабирование пропускной способности службы Stream Analytics — сценарий для компьютера Raspberry Pi


Рассмотрим следующий эксперимент, чтобы понять, как в типичном сценарии масштабируется пропускная способность заданий Stream Analytics для нескольких единиц потоковой передачи. Этот эксперимент состоит в следующем: данные датчиков (клиентов) отправляются в концентратор событий, служба ASA обрабатывает эти данные и отправляет предупреждение или статистические сведения в качестве выходных данных на другой концентратор событий.

Клиент отправляет синтезированные данные датчиков в формате JSON на концентраторы событий в службу Stream Analytics. Выходные данные также отправляются в формате JSON. Ниже приведен пример данных.

    {"devicetime":"2014-12-11T02:24:56.8850110Z","hmdt":42.7,"temp":72.6,"prss":98187.75,"lght":0.38,"dspl":"R-PI Olivier's Office"}

Запрос: "Send an alert when the light is switched off"

    SELECT AVG(lght),
	 “LightOff” as AlertText
	FROM input TIMESTAMP
	BY devicetime
	 WHERE
		lght< 0.05 GROUP BY TumblingWindow(second, 1)

Измерение пропускной способности. Пропускная способность в этом контексте — это объем входных данных, обрабатываемых службой Stream Analytics в определенный промежуток времени (10 минут). Чтобы обеспечить оптимальную пропускную способность для обработки входных данных, поток входных данных и запрос должны быть секционированы. В запрос также включается **COUNT()**, что позволяет подсчитать число обработанных событий ввода. Чтобы убедиться, что задание не просто ожидает поступления событий ввода, в каждую секцию концентратора событий ввода были предварительно загружены входные данные в достаточном объеме (300 МБ).

Ниже приведены результаты с увеличением количества единиц потоковой передачи и соответствующими данными о числе секций в концентраторах событий.

<table border="1">
<tr><th>Секции ввода</th><th>Секции вывода</th><th>Единицы потоковой передачи</th><th>Поддерживаемая пропускная способность
</th></td>

<tr><td>12</td>
<td>12</td>
<td>6</td>
<td>4,06&#160;МБ/с</td>
</tr>

<tr><td>12</td>
<td>12</td>
<td>12</td>
<td>8,06&#160;МБ/с</td>
</tr>

<tr><td>48</td>
<td>48</td>
<td>48</td>
<td>38,32&#160;МБ/с</td>
</tr>

<tr><td>192</td>
<td>192</td>
<td>192</td>
<td>172,67&#160;МБ/с</td>
</tr>

<tr><td>480</td>
<td>480</td>
<td>480</td>
<td>454,27&#160;МБ/с</td>
</tr>

<tr><td>720</td>
<td>720</td>
<td>720</td>
<td>609,69&#160;МБ/с</td>
</tr>
</table>

![img.stream.analytics.perfgraph][img.stream.analytics.perfgraph]

## Получение справки
За дополнительной помощью обращайтесь на наш [форум Azure Stream Analytics](https://social.msdn.microsoft.com/Forums/ru-RU/home?forum=AzureStreamAnalytics).


## Дальнейшие действия

- [Введение в Azure Stream Analytics](stream-analytics-introduction.md)
- [Приступая к работе с Azure Stream Analytics](stream-analytics-get-started.md)
- [Справочник по языку запросов Azure Stream Analytics](https://msdn.microsoft.com/library/azure/dn834998.aspx)
- [Справочник по API-интерфейсу REST управления Stream Analytics](https://msdn.microsoft.com/library/azure/dn835031.aspx)


<!--Image references-->

[img.stream.analytics.monitor.job]: ./media/stream-analytics-scale-jobs/StreamAnalytics.job.monitor.png
[img.stream.analytics.configure.scale]: ./media/stream-analytics-scale-jobs/StreamAnalytics.configure.scale.png
[img.stream.analytics.perfgraph]: ./media/stream-analytics-scale-jobs/perf.png
[img.stream.analytics.streaming.units.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsStreamingUnitsExample.jpg
[img.stream.analytics.preview.portal.settings.scale]: ./media/stream-analytics-scale-jobs/StreamAnalyticsPreviewPortalJobSettings.png

<!--Link references-->

[microsoft.support]: http://support.microsoft.com
[azure.management.portal]: http://manage.windowsazure.com
[azure.event.hubs.developer.guide]: http://msdn.microsoft.com/library/azure/dn789972.aspx

[stream.analytics.introduction]: stream-analytics-introduction.md
[stream.analytics.get.started]: stream-analytics-get-started.md
[stream.analytics.query.language.reference]: http://go.microsoft.com/fwlink/?LinkID=513299
[stream.analytics.rest.api.reference]: http://go.microsoft.com/fwlink/?LinkId=517301
 

<!---HONumber=AcomDC_0921_2016-->