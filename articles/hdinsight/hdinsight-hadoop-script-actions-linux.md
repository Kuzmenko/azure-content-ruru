<properties
    pageTitle="Разработка действий сценариев с помощью HDInsight на основе Linux | Microsoft Azure"
    description="Узнайте, как настроить кластеры HDInsight на основе Linux с помощью действия сценария."
    services="hdinsight"
    documentationCenter=""
    authors="Blackmist"
    manager="jhubbard"
    editor="cgronlun"/>

<tags
    ms.service="hdinsight"
    ms.workload="big-data"
    ms.tgt_pltfrm="na"
    ms.devlang="na"
    ms.topic="article"
    ms.date="09/13/2016"
    ms.author="larryfr"/>

# Разработка действий сценариев с помощью HDInsight

Действия сценариев предназначены для настройки кластеров Azure HDInsight. Для этого либо задаются параметры конфигурации кластера, либо в кластере устанавливаются дополнительные службы, инструменты или другое программное обеспечение. Действия сценария можно использовать во время создания кластера или в работающем кластере.

> [AZURE.NOTE] Информация, приведенная в этом документе, относится только к кластерам HDInsight на платформе Linux. Сведения об использовании действий сценариев в кластерах на платформе Windows см. в статье [Разработка действий сценариев с помощью HDInsight (Windows)](hdinsight-hadoop-script-actions.md).

## Что такое действия сценариев?

Действия сценариев — это сценарии Bash, которые Azure выполняет на узлах кластера, чтобы вносить изменения в конфигурацию или устанавливать программное обеспечение. Действие сценария выполняется от имени привилегированного пользователя и предоставляет права полного доступа к узлам кластера.

Действия сценариев могут применяться следующими способами:

| Используется для применения сценария… | При создании кластера… | В работающем кластере… |
| ----- |:-----:|:-----:|
| Портал Azure | ✓ | ✓ |
| Azure PowerShell | ✓ | ✓ |
| Инфраструктура CLI Azure | &nbsp; | ✓ |
| Пакет SDK для HDInsight .NET | ✓ | ✓ |
| Шаблон Azure Resource Manager | ✓ | &nbsp; |

Дополнительные сведения об использовании этих методов см. в статье о [настройке кластеров HDInsight с помощью действий сценариев](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="bestPracticeScripting"></a>Рекомендации по разработке сценариев

При разработке пользовательского скрипта для кластера HDInsight следует иметь в виду некоторые рекомендации.

- [Выбор версии Hadoop](#bPS1)
- [Предоставление стабильных ссылок на ресурсы сценария](#bPS2)
- [Использование предварительно скомпилированных ресурсов](#bPS4)
- [Обеспечение идемпотентности сценария настройки кластера](#bPS3)
- [Обеспечение высокого уровня доступности кластера](#bPS5)
- [Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure](#bPS6)
- [Запись информации в STDOUT и STDERR](#bPS7)
- [Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки](#bps8)
- [Использование логики повтора для восстановления после временных ошибок](#bps9)

> [AZURE.IMPORTANT] Действия скрипта должны быть завершены в течение 60 минут. В противном случае возникнет ошибка времени ожидания. Во время подготовки узла данный сценарий выполняется одновременно с другими процессами установки и настройки. Конкуренция за ресурсы, такие как ЦП или пропускная способность сети, может привести к затягиванию выполнения сценария по сравнению со временем его выполнения в среде разработки.

### <a name="bPS1"></a>Выбор целевой версии Hadoop

В различных версиях HDInsight используются различные версии служб Hadoop и компонентов. Если сценарий предполагает наличие определенной версии службы или компонента, то такой сценарий следует использовать только с версией HDInsight, включающей необходимые компоненты. Сведения о версиях компонентов, включенных в HDInsight, можно найти в документе [Версии компонентов HDInsight](hdinsight-component-versioning.md).

### <a name="bPS2"></a>Предоставление стабильных ссылок на ресурсы сценария

Вам нужно обеспечить доступность сценариев и ресурсов, используемых сценарием, в период существования кластера, а также неизменность версий этих файлов. Эти ресурсы необходимы, если во время операций масштабирования в кластер добавляются новые узлы.

Мы советуем скачивать и архивировать все данные в свою учетную запись хранения Azure.

> [AZURE.IMPORTANT] Используемая учетная запись хранения должна быть учетной записью хранения по умолчанию для кластера или общедоступным и открытым только для чтения контейнером в другой учетной записи хранения.

В частности, примеры, предоставляемые корпорацией Майкрософт, хранятся в учетной записи хранения по адресу [https://hdiconfigactions.blob.core.windows.net/](https://hdiconfigactions.blob.core.windows.net/). Эта учетная запись является открытым и доступным только для чтения контейнером, который обслуживает команда HDInsight.

### <a name="bPS4"></a>Использование предварительно скомпилированных ресурсов

Чтобы сократить время выполнения сценария, избегайте операций, компилирующих ресурсы из исходного кода. Вместо этого выполните предварительную компиляцию ресурсов и сохраните версию в форме двоичного файла в хранилище больших двоичных объектов Azure, чтобы его можно быстро скачать в кластер из сценария.

### <a name="bPS3"></a>Обеспечение идемпотентности сценария настройки кластера

Сценарии должны быть идемпотентными. Имеется в виду, что при многократном выполнении в каждом случае сценарий должен обеспечивать возврат кластера к одному и тому же состоянию.

Например, если пользовательский сценарий во время своего первого запуска установил приложение в папку /usr/local/bin, то при каждом последующем запуске сценарий должен проверять, существует ли приложение в папке /usr/local/bin, и только после этого переходить к следующим шагам.

### <a name="bPS5"></a>Обеспечение высокого уровня доступности кластера

В кластерах HDInsight под управлением Linux есть два головных узла, активных в пределах кластера. Действия сценария выполняются на обоих узлах. Если устанавливаемым компонентам требуется только один головной узел, то сценарий должен предусматривать установку компонента только на один из двух головных узлов кластера.

> [AZURE.IMPORTANT] Стандартные службы, устанавливаемые вместе с HDInsight, выполняют отработку отказа между двумя узлами. Однако эта функция не распространяется на пользовательские компоненты, устанавливаемые при выполнении действий сценария. Если требуется высокая доступность компонентов, устанавливаемых с помощью действий сценария, необходимо реализовать собственный механизм отработки отказа, использующий два доступных головных узла.

### <a name="bPS6"></a>Настройка пользовательских компонентов для использования хранилища больших двоичных объектов Azure

Компоненты, устанавливаемые на кластере, могут по умолчанию использовать хранилище распределенной файловой системы Hadoop (HDFS). HDInsight в качестве хранилища по умолчанию использует хранилище BLOB-объектов Azure (WASB). Это обеспечивает совместимую с HDFS файловую систему, которая сохраняет данные даже после удаления кластера. Необходимо настроить устанавливаемые компоненты, чтобы использовать WASB вместо HDFS.

Пример ниже копирует файл giraph-examples.jar из локальной файловой системы в хранилище WASB.

    hadoop fs -copyFromLocal /usr/hdp/current/giraph/giraph-examples.jar /example/jars/

### <a name="bPS7"></a>Запись информации в STDOUT и STDERR

Данные, записываемые в STDOUT и STDERR при выполнении сценария, заносятся в журнал и могут быть просмотрены с помощью веб-интерфейса Ambari.

> [AZURE.NOTE] Веб-интерфейс Ambari доступен только в том случае, если кластер успешно создан. Если во время создания кластера используется действие сценария и создание завершается ошибкой, ознакомьтесь с другими способами доступа к данным журнала в разделе по устранению неполадок [Настройка кластеров HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md#troubleshooting).

Большинство программ и пакетов установки добавляют данные в STDOUT и STDERR по умолчанию, однако вам может потребоваться добавить дополнительные записи в журнал. Для отправки текста в STDOUT используйте `echo`. Например:

        echo "Getting ready to install Foo"

По умолчанию ключевое слово `echo` отправляет строку в STDOUT. Чтобы направить строку в STDERR, добавьте `>&2` перед `echo`. Например:

        >&2 echo "An error occurred installing Foo"

Эта команда перенаправляет данные из STDOUT (значение 1, которое является значением по умолчанию, поэтому не указано здесь) в STDERR (2). Дополнительные сведения о перенаправлении ввода-вывода см. на странице [http://www.tldp.org/LDP/abs/html/io-redirection.html](http://www.tldp.org/LDP/abs/html/io-redirection.html).

Дополнительные сведения о просмотре журналов, созданных действиями сценария, см. в статье о [настройке кластеров HDInsight с помощью действий сценария](hdinsight-hadoop-customize-cluster-linux.md#troubleshooting).

###<a name="bps8"></a> Сохранение файлов в формате ASCII с использованием LF в качестве символа завершения строки

Сценарии Bash должны храниться в формате ASCII. Для завершения строк в этом файле используется символ LF. Если в файлах используется кодировка UTF-8, которая допускает наличие метки порядка байтов в начале файла и использование символа CRLF для завершения строки (зачастую эта кодировка используется редакторами Windows), то сценарий завершится с ошибками, аналогичными приведенным ниже.

    $'\r': command not found
    line 1: #!/usr/bin/env: No such file or directory

###<a name="bps9"></a> Использование логики повтора для восстановления после временных ошибок

При скачивании файлов, установке пакетов с помощью apt-get или других действиях, которые передают данные через Интернет, операция может завершиться ошибкой из-за временной ошибки сети. Например, удаленный ресурс, с которым вы обмениваетесь данными, может находиться в процессе отработки отказа на резервный узел.

Чтобы сделать свой сценарий устойчивым к временным ошибкам, можно реализовать логику повтора. Ниже приведен пример функции, которая будет выполнять передаваемую в нее команду и (если команда завершается ошибкой) повторять ее до трех раз. Она будет ждать две секунды между попытками.

    #retry
    MAXATTEMPTS=3

    retry() {
        local -r CMD="$@"
        local -i ATTMEPTNUM=1
        local -i RETRYINTERVAL=2

        until $CMD
        do
            if (( ATTMEPTNUM == MAXATTEMPTS ))
            then
                    echo "Attempt $ATTMEPTNUM failed. no more attempts left."
                    return 1
            else
                    echo "Attempt $ATTMEPTNUM failed! Retrying in $RETRYINTERVAL seconds..."
                    sleep $(( RETRYINTERVAL ))
                    ATTMEPTNUM=$ATTMEPTNUM+1
            fi
        done
    }

Ниже приведены примеры использования этой функции.

    retry ls -ltr foo

    retry wget -O ./tmpfile.sh https://hdiconfigactions.blob.core.windows.net/linuxhueconfigactionv02/install-hue-uber-v02.sh

## <a name="helpermethods"></a>Вспомогательные методы для пользовательских сценариев

Вспомогательные методы действий сценариев — это служебные программы, которые можно использовать при создании пользовательских скриптов. Их определение приведено на странице [https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh](https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh). Эти методы могут быть включены в скрипты с помощью следующей команды:

    # Import the helper method module.
    wget -O /tmp/HDInsightUtilities-v01.sh -q https://hdiconfigactions.blob.core.windows.net/linuxconfigactionmodulev01/HDInsightUtilities-v01.sh && source /tmp/HDInsightUtilities-v01.sh && rm -f /tmp/HDInsightUtilities-v01.sh

Эта команда открывает доступ к следующим вспомогательным приложениям, доступным для использования в сценарии.

| Назначение вспомогательного приложения | Описание |
| ------------ | ----------- |
| `download_file SOURCEURL DESTFILEPATH [OVERWRITE]` | Загружает файл из исходного URL-адреса и сохраняет его в указанное расположение. При этом по умолчанию существующий файл не перезаписывается. |
| `untar_file TARFILE DESTDIR` | Извлекает TAR-файл (с помощью `-xf`) в папку назначения. |
| `test_is_headnode` | При запуске на головном узле кластера возвращает значение 1, в противном случае — 0. |
| `test_is_datanode` | Если текущий узел является узлом данных (рабочим узлом), то возвращается значение 1, в противном случае — 0. |
| `test_is_first_datanode` | Если текущий узел является первым узлом данных (рабочим узлом с именем workernode0), возвращается значение 1, в противном случае — 0. |
| `get_headnodes` | Возвращает полное доменное имя головных узлов в кластере. Имена содержат разделители-запятые. При возникновении ошибки возвращается пустая строка. |
| `get_primary_headnode` | Возвращает полное доменное имя основного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_secondary_headnode` | Возвращает полное доменное имя дополнительного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_primary_headnode_number` | Возвращает числовой суффикс основного головного узла. При возникновении ошибки возвращается пустая строка. |
| `get_secondary_headnode_number` | Возвращает числовой суффикс дополнительного головного узла. При возникновении ошибки возвращается пустая строка. |

## <a name="commonusage"></a>Общие варианты использования

В этом разделе содержится руководство по реализации некоторых общих вариантов использования, которые могут понадобиться при написании пользовательского сценария.

### Передача параметров в сценарий

В некоторых случаях для сценария требуется указывать параметры. Например, для извлечения сведений из интерфейса Ambari REST API может потребоваться пароль администратора кластера.

Параметры, передаваемые в скрипт, называются _позиционными параметрами_, т. е. `$1` соответствует первому параметру, `$2` — второму и т. д. Значение `$0` содержит имя самого сценария.

Значения, передаваемые в сценарий в качестве параметров, должны быть заключены в одинарные кавычки ('). Эти значения будут рассматриваться как литералы, и такие символы, как «!», не будут интерпретироваться как специальные.

### Настройка переменных среды

Настройка переменной среды выполняется следующим образом.

    VARIABLENAME=value

Где VARIABLENAME — имя переменной. После этого вы можете использовать `$VARIABLENAME` для доступа к переменной. Например, чтобы присвоить значение позиционного параметра переменной среды с именем PASSWORD, воспользуйтесь следующей конструкцией.

    PASSWORD=$1

Для последующего доступа к данным используйте `$PASSWORD`.

Переменные среды, заданные в сценарии, существуют только в пределах области сценария. В некоторых случаях может потребоваться добавить переменные среды, которые значимы на уровне системы и значение которых сохранится после выполнения сценария. Обычно это нужно для того, чтобы пользователи, подключаемые к кластеру через SSH, могли использовать установленные сценарием компоненты. Системная переменная создается добавлением переменной среды в папку `/etc/environment`. Например, следующая конструкция добавляет переменную __HADOOP\_CONF\_DIR__.

    echo "HADOOP_CONF_DIR=/etc/hadoop/conf" | sudo tee -a /etc/environment

### Доступ к расположениям, в которых хранятся пользовательские сценарии

Сценарии для настройки кластера должны находиться в учетной записи хранения по умолчанию для кластера или в общедоступном и открытом только для чтения контейнере другой учетной записи хранения. Если сценарий получает доступ к ресурсам в другом расположении, это расположение должно быть общедоступным (или по крайней мере открытым только для чтения). Например, может потребоваться загрузить файл в кластер с помощью метода `download_file`.

Сохранение файла в учетной записи хранения Azure, доступной кластеру (например, в учетной записи хранения по умолчанию), обеспечит быстрый доступ к нему, так как это хранилище находится в сети Azure.

## <a name="deployScript"></a>Контрольный список для развертывания действия сценария

Ниже приведены шаги, которые использовались при подготовке к развертыванию этих скриптов.

- Поместите файлы, содержащие пользовательские скрипты, в месте, доступном из узлов кластера во время развертывания. Это может быть любая из используемых по умолчанию или дополнительных учетных записей хранения, указанных во время развертывания кластера, или другой общедоступный контейнер хранилища.

- Добавьте проверки в сценарии, чтобы гарантировать их идемпотентное выполнение, т. е. возможность многократного выполнения сценария на одном и том же узле.

- Используйте папку для временных файлов, например /tmp, чтобы хранить скачанные файлы, используемый сценариями. После выполнения сценариев очистите эту папку.

- В случае изменений параметров на уровне операционной системы или файлов конфигурации службы Hadoop может потребоваться перезапуск служб HDInsight. За счет этого службы HDInsight смогут автоматически установить любые параметры уровня операционной системы, например заданные в сценариях переменные среды.

## <a name="runScriptAction"></a>Как запустить действие сценария

Действия сценариев можно использовать для настройки кластеров HDInsight с помощью портала Azure, Azure PowerShell, шаблонов Azure Resource Manager (ARM) или пакета SDK .NET для HDInsight. Указания см. в руководстве по [использованию действий сценария](hdinsight-hadoop-customize-cluster-linux.md).

## <a name="sampleScripts"></a>Примеры пользовательских сценариев

Корпорация Майкрософт предоставляет примеры скриптов для установки компонентов в кластере HDInsight. Примеры скриптов и инструкции по их использованию доступны по приведенным ниже ссылкам:

- [Установка и использование Hue в кластерах HDInsight](hdinsight-hadoop-hue-linux.md)
- [Установка и использование R в кластерах HDInsight Hadoop](hdinsight-hadoop-r-scripts-linux.md)
- [Установка и использование Solr в кластерах HDInsight](hdinsight-hadoop-solr-install-linux.md)
- [Установка и использование Giraph в кластерах HDInsight](hdinsight-hadoop-giraph-install-linux.md)

> [AZURE.NOTE] Приведенные выше документы относятся только к кластерам HDInsight под управлением Linux. Сведения о скриптах, предназначенных для HDInsight под управлением Windows, см. в статье [Разработка действий скриптов с помощью HDInsight (Windows)](hdinsight-hadoop-script-actions.md) или по ссылкам, приведенным в начале каждой статьи.

##Устранение неполадок

Ниже перечислены ошибки, которые могут возникнуть при использовании ваших сценариев.

__Ошибка__: `$'\r': command not found`. Иногда дополняется фразой `syntax error: unexpected end of file`.

_Причина._ Эта ошибка возникает, когда для завершения строк в сценарии используется символ CRLF. В системах UNIX для завершения строк допускается только символ LF.

Зачастую эта проблема возникает при написании сценария в среде Windows, так как в текстовых редакторах для этой системы CRLF является стандартным символом завершения строки.

_Решение._ Если в вашем текстовом редакторе имеется функция выбора формата Unix или использования символа LF для завершения строк, воспользуйтесь ею. Кроме того, в системе Unix вы можете использовать следующие команды изменения CRLF на LF.

> [AZURE.NOTE] Для замены символов CRLF на LF могут использоваться следующие аналогичные команды. Выберите подходящий вариант в зависимости от наличия в системе соответствующих служебных программ.

| Команда | Примечания |
| ------- | ----- |
| `unix2dos -b INFILE` | Для исходного файла будет создана резервная копия с расширением BAK. |
| `tr -d '\r' < INFILE > OUTFILE` | В файле OUTFILE для окончания строк будут использоваться только символы LF. |
| `perl -pi -e 's/\r\n/\n/g' INFILE` | Эта команда изменит исходный файл без создания нового файла. |
| ```sed 's/$'"/`echo \\r`/" INFILE > OUTFILE``` | В файле OUTFILE для окончания строк будут использоваться только символы LF.

__Ошибка__: `line 1: #!/usr/bin/env: No such file or directory`.

_Причина._ Эта ошибка возникает, если скрипт сохранен в кодировке UTF-8 с меткой порядка байтов (BOM).

_Решение._ Сохраните файл в формате ASCII или UTF-8 без метки порядка байтов. Кроме того, для создания нового файла без метки порядка байтов в системе Linux или Unix вы можете использовать следующую команду.

    awk 'NR==1{sub(/^\xef\xbb\xbf/,"")}{print}' INFILE > OUTFILE

В приведенной выше команде замените __INFILE__ на файл с меткой порядка байтов. Для __OUTFILE__ укажите новое имя файла, который будет содержать скрипт без метки порядка байтов.

## <a name="seeAlso"></a>Дальнейшие действия

* Узнайте, как [настраивать кластеры HDInsight с помощью действия сценария](hdinsight-hadoop-customize-cluster-linux.md).

* Используйте [справочник по пакету SDK .NET для HDInsight](https://msdn.microsoft.com/library/mt271028.aspx), чтобы узнать больше о создании приложений .NET, которые управляют HDInsight.

* Используйте [REST API HDInsight](https://msdn.microsoft.com/library/azure/mt622197.aspx), чтобы узнать, как использовать REST для выполнения операций управления кластерами HDInsight.

<!---HONumber=AcomDC_0921_2016-->