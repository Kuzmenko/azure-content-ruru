<properties
   pageTitle="Советы по использованию Hadoop в HDInsight на платформе Linux | Microsoft Azure"
   description="Советы по использованию кластеров HDInsight (Hadoop) на базе Linux в привычной среде Linux, выполняемой в облаке Azure."
   services="hdinsight"
   documentationCenter=""
   authors="Blackmist"
   manager="jhubbard"
   editor="cgronlun"
   tags="azure-portal"/>

<tags
   ms.service="hdinsight"
   ms.devlang="na"
   ms.topic="article"
   ms.tgt_pltfrm="na"
   ms.workload="big-data"
   ms.date="09/13/2016"
   ms.author="larryfr"/>

# Сведения об использовании HDInsight в Linux

Кластеры Azure HDInsight под управлением Linux предоставляют Hadoop в привычной среде Linux, выполняемой в облаке Azure. Для большинства задач они должны работать так же, как и любые другие установки Hadoop в Linux. В этом документе рассматриваются определенные отличия, которые при этом следует учитывать.

##Предварительные требования

При выполнении многих действий, описанных в этом документе, используются следующие служебные программы, которые может потребоваться установить в системе:

* [cURL](https://curl.haxx.se/) — используется для взаимодействия с веб-службами;
* [jq](https://stedolan.github.io/jq/) — используется для анализа документов JSON.
* [Azure CLI](../xplat-cli-install.md) используется для удаленного управления службами Azure.

	[AZURE.INCLUDE [use-latest-version](../../includes/hdinsight-use-latest-powershell-and-cli.md)]

## Имена доменов

При подключении к кластеру из Интернета следует использовать полное доменное имя (FQDN) **&lt;имя\_кластера>.azurehdinsight.net** или (только для SSH) **&lt;имя\_кластера>.aurehdinsight.net**.

На внутреннем уровне каждый узел в кластере имеет имя, назначаемое при конфигурации кластера. Чтобы найти имена кластеров, посетите страницу __Узлы__ пользовательского веб-интерфейса Ambari или воспользуйтесь следующей командой, чтобы вернуть список узлов из API REST Ambari:

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/hosts" | jq '.items[].Hosts.host_name'

Замените __ПАРОЛЬ__ паролем учетной записи администратора, а __ИМЯ\_КЛАСТЕРА__ — именем кластера. Возвращает документ JSON, который содержит список узлов в кластере, а затем jq извлекает значение элемента `host_name` для каждого узла в кластере.

Если требуется найти имя узла для конкретной службы, можно запросить Ambari для этого компонента. Например, чтобы найти узлы для узла имен HDFS, воспользуйтесь следующей командой.

    curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/services/HDFS/components/NAMENODE" | jq '.host_components[].HostRoles.host_name'

Это возвращает документ JSON с описанием службы, а затем jq извлекает только значение `host_name` для узлов.

## Удаленный доступ к службам

* **Ambari (веб-версия)** — https://&lt;clustername>.azurehdinsight.net

	Выполните аутентификацию, а затем войдите в Ambari. Используйте для этого имя пользователя и пароль администратора кластера.

	При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

	> [AZURE.IMPORTANT] Хотя Ambari для кластера доступен напрямую через Интернет, некоторые функциональные возможности зависят от доступа к узлам по внутреннему доменному имени, используемому в кластере. Так как это внутреннее доменное имя, а не общедоступное, вы получите ошибку "сервер не найден", если попытаетесь получить доступ к некоторым функциям сервера через Интернет.
	>
	> Чтобы получить доступ ко всем функциям веб-интерфейса Ambari, используйте туннелирование SSH для проксирования веб-трафика на головной узел кластера. Дополнительные сведения см. в статье [Использование туннелирования SSH для доступа к веб-интерфейсу Ambari, ResourceManager, JobHistory, NameNode, Oozie и другим веб-интерфейсам](hdinsight-linux-ambari-ssh-tunnel.md).

* **Ambari (REST)** — https://&lt;clustername>.azurehdinsight.net/ambari

	> [AZURE.NOTE] Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
	>
	> При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **WebHCat (Templeton)** — https://&lt;clustername>.azurehdinsight.net/templeton

	> [AZURE.NOTE] Выполните аутентификацию, используя имя пользователя и пароль администратора кластера.
	>
	> При аутентификации используется открытый текст. Всегда используйте протокол HTTPS, чтобы обеспечить безопасное подключение.

* **SSH** — &lt;имя\_кластера>-ssh.azurehdinsight.net через порт 22 или 23. Для подключения к основному головному узлу используется порт 22, а для подключения к дополнительному — порт 23. Дополнительные сведения о головных узлах см. в статье [Доступность и надежность кластеров Hadoop в HDInsight](hdinsight-high-availability-linux.md).

	> [AZURE.NOTE] Доступ к головным узлам кластера можно получить только по протоколу SSH с клиентского компьютера. После подключения с головного узла можно получить доступ к рабочим узлам по протоколу SSH.

## Местоположения файлов

Связанные с Hadoop файлы можно найти на узлах кластера в папке `/usr/hdp`. Этот каталог содержит следующие подкаталоги:

* __2.2.4.9-1__. Имя этого каталога соответствует версии платформы данных Hortonworks, используемой в HDInsight, поэтому номер в кластере может отличаться от указанного здесь.
* __Current__: этот каталог содержит ссылки на каталоги в каталоге __2.2.4.9-1__ и существует для того, чтобы не приходилось вводить номер версии (который может измениться) каждый раз, когда нужно получить доступ к файлу.

Примеры данных и JAR-файлы можно найти в распределенной файловой системе Hadoop (HDFS) или в хранилище BLOB-объектов Azure в папке /example или wasbs:///example.

## Рекомендации при работе с распределенной файловой системой Hadoop, хранилищем больших двоичных объектов Azure, а также рекомендации по использованию хранилища

В большинстве дистрибутив Hadoop распределенная файловая система Hadoop реализуется на базе локального хранилища на компьютерах в кластере. Несмотря на эффективность, в случае облачного решения с почасовой или поминутной платой за вычислительные ресурсы такой подход может оказаться весьма затратным.

HDInsight использует хранилище больших двоичных объектов Azure как хранилище по умолчанию, что дает следующие преимущества:

* недорогое долговременное хранение;

* доступность из внешних служб, например веб-сайтов, служебных программ для отправки или скачивания файлов, пакетов SDK для различных языков и веб-браузеров.

Поскольку это хранилище по умолчанию для HDInsight, в большинстве случаев его можно использовать без какой-либо специальной подготовки. Например, следующая команда отображает список файлов в папке **/example/data**, которая хранится в хранилище больших двоичных объектов Azure:

	hdfs dfs -ls /example/data

Возможно, для некоторых команд нужно будет указать, что вы используете хранилище больших двоичных объектов. Для этого можно добавить к команде префикс **wasb://** или **wasbs://**.

HDInsight также позволяет связать несколько учетных записей хранилища больших двоичных объектов с кластером. Для доступа к данным из учетной записи хранилища больших двоичных объектов, отличной от заданной по умолчанию, можно использовать формат **wasbs://&lt;container-name>@&lt;имя\_учетной\_записи>.blob.core.windows.net/**. Например, ниже будет перечислено содержимое каталога **/example/data** для указанного контейнера и учетной записи хранилища больших двоичных объектов.

	hdfs dfs -ls wasbs://mycontainer@mystorage.blob.core.windows.net/example/data

### Какие хранилища больших двоичных объектов используются в кластере

При создании кластера вы выбираете существующие учетную запись хранения Azure и контейнер, или можете создать новые. Если вы забудете, что именно выбрали, то сможете найти используемые по умолчанию учетную запись хранения и контейнер с помощью интерфейса API REST Ambari.

1. Для получения информации о конфигурации HDFS используйте команду curl и выполните фильтрацию с помощью [jq](https://stedolan.github.io/jq/):

        curl -u admin:PASSWORD -G "https://CLUSTERNAME.azurehdinsight.net/api/v1/clusters/CLUSTERNAME/configurations/service_config_versions?service_name=HDFS&service_config_version=1" | jq '.items[].configurations[].properties["fs.defaultFS"] | select(. != null)'
    
    > [AZURE.NOTE] Эта команда возвращает первую конфигурацию, применяемую к серверу (`service_config_version=1`), который будет содержать эти сведения. Чтобы получить значение, которое было изменено после создания кластера, может потребоваться перечислить версии конфигурации и получить последнюю из них.

    Будет возвращено значение, аналогичное приведенному ниже, где __CONTAINER__ — это контейнер по умолчанию, а __ACCOUNTNAME__ — имя учетной записи хранения Azure.

        wasbs://CONTAINER@ACCOUNTNAME.blob.core.windows.net

1. Получите группу ресурсов для учетной записи хранения с помощью [интерфейса командной строки Azure](../xplat-cli-install.md). В следующей команде замените __ACCOUNTNAME__ именем учетной записи хранения, полученным из Ambari:

        azure storage account list --json | jq '.[] | select(.name=="ACCOUNTNAME").resourceGroup'
    
    Эта команда возвращает имя группы ресурсов для учетной записи.
    
    > [AZURE.NOTE] Если эта команда не возвращает данные, может потребоваться изменить режим интерфейса командной строки Azure на режим диспетчера ресурсов Azure и запустить команду еще раз. Чтобы переключиться в режим диспетчера ресурсов Azure, выполните следующую команду:
    >
    > `azure config mode arm`
    
2. Получите ключ для учетной записи хранения. Замените __GROUPNAME__ именем группы ресурсов, полученным на предыдущем шаге. Замените __ACCOUNTNAME__ именем учетной записи хранения:

        azure storage account keys list -g GROUPNAME ACCOUNTNAME --json | jq '.[0].value'

    Эта команда возвращает первичный ключ для учетной записи.

Сведения о хранилище также можно найти на портале Azure.

1. На [портале Azure](https://portal.azure.com/) выберите свой кластер HDInsight.

2. В разделе __Основные сведения__ нажмите кнопку __Все параметры__.

3. В разделе __Параметры__ выберите __Ключи к хранилищу Azure__.

4. В разделе __Ключи к хранилищу Azure__ выберите одну из перечисленных учетных записей хранения. Отобразится информация о выбранной учетной записи хранения.

5. Щелкните значок ключа. Отобразятся ключи для этой учетной записи хранения.

### Как получить доступ к хранилищу больших двоичных объектов

Получить доступ к большим двоичным объектам можно не только с помощью команды Hadoop из кластера, но и множеством других способов:

* [CLI Azure для Mac, Linux и Windows](../xplat-cli-install.md) — это набор кроссплатформенных команд для работы с Azure. После установки используйте команду `azure storage` для получения информации по использованию хранилища, а команду `azure blob` — для получения информации о больших двоичных объектах.

* [blobxfer.py](https://github.com/Azure/azure-batch-samples/tree/master/Python/Storage) — cценарий Python для работы с большими двоичными объектами в хранилище Azure.

* Различные пакеты SDK:

	* [Java](https://github.com/Azure/azure-sdk-for-java)

	* [Node.js](https://github.com/Azure/azure-sdk-for-node)

	* [PHP](https://github.com/Azure/azure-sdk-for-php)

	* [Python](https://github.com/Azure/azure-sdk-for-python)

	* [Ruby](https://github.com/Azure/azure-sdk-for-ruby)

	* [.NET](https://github.com/Azure/azure-sdk-for-net)

* [REST API службы хранилища](https://msdn.microsoft.com/library/azure/dd135733.aspx)

##<a name="scaling"></a>Масштабирование кластера

Масштабирование кластера позволяет вам изменить число узлов данных в кластере, который работает в Azure HDInsight. При этом не требуется удалять и повторно создавать кластер.

Операции масштабирования можно выполнять параллельно с другими заданиями и процессами, выполняющимися в кластере.

Масштабирование влияет на разные типы кластеров по-разному:

* __Hadoop__. При уменьшении количества узлов в кластере некоторые службы в нем перезапускаются. Это может привести к сбою всех выполняющихся и ожидающих заданий при завершении операции масштабирования. После завершения операции вы можете повторно отправить задания.

* __HBase__. В течение нескольких минут после завершения операции масштабирования автоматически выполняется балансировка нагрузки на региональные серверы. Чтобы вручную распределить нагрузку между региональными серверами, выполните следующие действия.

	1. Подключитесь к кластеру HDInsight по протоколу SSH. Дополнительные сведения об использовании SSH с HDInsight см. в следующих статьях:

		* [Использование SSH с HDInsight в Linux, Unix и Mac OS X](hdinsight-hadoop-linux-use-ssh-unix.md)

		* [Использование SSH с HDInsight в Windows](hdinsight-hadoop-linux-use-ssh-windows.md)

	1. Чтобы запустить оболочку HBase, используйте следующую команду:

			hbase shell

	2. После загрузки оболочки HBase запустите балансировку нагрузки между региональными серверами вручную, используя следующую команду:

			balancer

* __Storm__. После завершения операции масштабирования следует запустить повторную балансировку для всех запущенных топологий Storm. Это позволяет настроить параметры параллелизма для топологий на основе нового количества узлов в кластере. Чтобы повторно выполнить балансировку выполняющихся топологий, используйте один из следующих вариантов.

	* __SSH__. Подключитесь к серверу и запустите балансировку для топологии, используя следующую команду:

			storm rebalance TOPOLOGYNAME

		Можно также указать параметры для переопределения подсказок параллелизма, изначально предоставляемых топологией. Например, `storm rebalance mytopology -n 5 -e blue-spout=3 -e yellow-bolt=10` перенастроит топологию с учетом 5 рабочих процессов, 3 исполнителей для компонента blue-spout и 10 исполнителей для компонента yellow-bolt.

	* __Пользовательский интерфейс Storm__. Чтобы запустить балансировку для топологии из интерфейса Storm, выполните следующие действия.

		1. В веб-браузере откройте страницу \_\_https://CLUSTERNAME.azurehdinsight.net/stormui__, где CLUSTERNAME — это имя вашего кластера Storm. При появлении запроса введите имя администратора кластера HDInsight (admin) и пароль, указанный при создании кластера.

		3. Выберите топологию, для которой нужно выполнить повторную балансировку, и нажмите кнопку __Перераспределить__. Введите задержку перед выполнением операции перебалансировки.

Подробные сведения о масштабировании кластера HDInsight см. в следующих статьях.

* [Управление кластерами Hadoop в HDInsight с помощью портала Azure](hdinsight-administer-use-portal-linux.md#scaling)

* [Управление кластерами Hadoop в HDInsight с помощью Azure PowerShell](hdinsight-administer-use-command-line.md#scaling)

## Как установить Hue (или другой компонент Hadoop)?

HDInsight — управляемая служба. Это означает, что при возникновении проблемы Azure может автоматически удалить и повторно подготовить узлы в кластере. Поэтому не рекомендуется вручную устанавливать компоненты непосредственно на узлах кластера. При необходимости установить указанные ниже компоненты используйте [действия сценариев HDInsight](hdinsight-hadoop-customize-cluster.md).

* Служба или веб-сайт, например Spark или Hue.
* Компонент, для которого необходимо изменить конфигурацию на нескольких узлах кластера. Например, обязательная переменная среды, создание каталога ведения журналов или создание файла конфигурации.

Действия сценариев — это сценарии Bash, которые выполняются при подготовке кластера и которые можно использовать для установки и настройки дополнительных компонентов в кластере. Доступны примеры скриптов для установки следующих компонентов:

* [Hue](hdinsight-hadoop-hue-linux.md)
* [Giraph](hdinsight-hadoop-giraph-install-linux.md)
* [Solr](hdinsight-hadoop-solr-install-linux.md)

Сведения о разработке собственных действий сценариев см. в статье [Разработка действий сценариев с помощью HDInsight](hdinsight-hadoop-script-actions-linux.md).

###JAR-файлы

Некоторые технологии Hadoop предоставляются в автономных JAR-файлах, которые содержат функции, используемые в рамках задания MapReduce или из Pig и Hive. Несмотря на то что их можно установить с помощью действий сценариев, зачастую они не требуют установки. После подготовки можно просто отправить их в кластер для непосредственного использования. Если вы хотите, чтобы компонент не исчез при повторном создании образа кластера, можно сохранить JAR-файл в WASB.

Например, если необходимо использовать последнюю версию [DataFu](http://datafu.incubator.apache.org/), можно скачать JAR-файл, содержащий проект, и отправить его в кластер HDInsight. Далее следуйте инструкциям в документации для DataFu по использованию его в Pig или Hive.

> [AZURE.IMPORTANT] Некоторые компоненты, представляющие собой автономные JAR-файлы, предоставляются вместе с HDInsight, но не в пути. Если вам необходим определенный компонент, можно выполнить его поиск в кластере.
>
> ```find / -name *componentname*.jar 2>/dev/null```
>
> В результате выполнения этой команды будут возвращены пути к соответствующим JAR-файлам.

Если кластер уже содержит версию компонента в виде автономного JAR-файла, но вам необходимо использовать другую версию, вы можете отправить новую версию компонента в кластер и попробовать использовать его в ваших заданиях.

> [AZURE.WARNING] Компоненты, предоставляемые вместе с кластером HDInsight, поддерживаются в полном объеме. Техническая поддержка Майкрософт поможет вам выявить и решить проблемы, связанные с этими компонентами.
>
> Настраиваемые компоненты получают ограниченную коммерчески оправданную поддержку, способствующую дальнейшей диагностике проблемы. В результате проблема может быть устранена, либо вас могут попросить воспользоваться доступными каналами по технологиям с открытым исходным кодом, чтобы связаться с экспертами в данной области. Можно использовать ряд сайтов сообществ, например [форум MSDN по HDInsight](https://social.msdn.microsoft.com/Forums/azure/ru-RU/home?forum=hdinsight) и [http://stackoverflow.com](http://stackoverflow.com). Кроме того, для проектов Apache есть соответствующие сайты по адресу [http://apache.org](http://apache.org), например для [Hadoop](http://hadoop.apache.org/) и [Spark](http://spark.apache.org/).

## Дальнейшие действия

* [Миграция из кластера HDInsight под управлением Windows в кластер HDInsight под управлением Linux](hdinsight-migrate-from-windows-to-linux.md)
* [Использование Hive с HDInsight](hdinsight-use-hive.md)
* [Использование Pig с HDInsight](hdinsight-use-pig.md)
* [Использование заданий MapReduce с HDInsight](hdinsight-use-mapreduce.md)

<!---HONumber=AcomDC_0921_2016-->